{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start a SparkSession and configure it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark.sql is a module, SparkSession is a class in it\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavior of SparkConf() and spark.conf\n",
    "\n",
    "Before starting a SparkSession, `SparkConf().getAll()` returns an empty dict_item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparkConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add configuration key-value pairs by calling the `set()` or `setAll()` method of `SparkConf()`, which returns a new `SparkConf` object, which is then passed to `.config` during the building of the `SparkSession`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.maxResultSize', '10g'),\n",
       " ('spark.master', 'local[4]'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.driver.memory', '2g'),\n",
       " ('spark.app.name', 'Learn Spark'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_conf = SparkConf().setAll([('spark.driver.maxResultSize', '10g'),('spark.driver.memory','2g')])\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local[4]') \\\n",
    "        .appName('Learn Spark') \\\n",
    "        .config(conf=my_conf) \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "\n",
    "SparkConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the configuration after the `SparkSession` was created, use the `SparkSession.conf` interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10g'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get('spark.driver.maxResultSize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5g'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.set('spark.driver.maxResultSize', '5g')\n",
    "spark.conf.get('spark.driver.maxResultSize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But calling `spark.conf.set` only affect the configuration of the particular `SparkSession`. It will NOT change `my_conf` or the result of calling `SparkConf()` in the future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.maxResultSize', '10g'),\n",
       " ('spark.master', 'local[4]'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.driver.memory', '2g'),\n",
       " ('spark.app.name', 'Learn Spark'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparkConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a new session with different configuration is created, it won't change the system setting. In other words, the result of `SparkConf()` is still the same with the first `my_conf` created by `SparkConf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.master', 'local[4]'), ('spark.sql.catalogImplementation', 'hive'), ('spark.driver.memory', '2g'), ('spark.driver.maxResultSize', '2g'), ('spark.app.name', 'Learn Spark'), ('spark.submit.deployMode', 'client'), ('spark.ui.showConsoleProgress', 'true')] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('spark.driver.maxResultSize', '10g'),\n",
       " ('spark.master', 'local[4]'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.driver.memory', '2g'),\n",
       " ('spark.app.name', 'Learn Spark'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_conf = SparkConf().set('spark.driver.maxResultSize','2g')\n",
    "print(new_conf.getAll(), '\\n')\n",
    "\n",
    "spark2 = SparkSession.builder \\\n",
    "        .master('local[4]') \\\n",
    "        .appName('Learn Spark') \\\n",
    "        .config(conf=new_conf) \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "\n",
    "SparkConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Configurations and Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Spark Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use sparkContext interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only output ERROR into log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel('ERROR') # equivalent to set up the log4j.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize the max file size the excutors send to driver\n",
    "\n",
    "**To solve the Error**: Total size of serialized results of tasks is bigger than spark.driver.maxResultSize\n",
    "\n",
    "**Solution**: Set `spark.driver.maxResultSize` to a larger value when starting `SparkSession`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3g'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.set('spark.driver.maxResultSize', '3g')\n",
    "spark.conf.get('spark.driver.maxResultSize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD\n",
    "\n",
    "## Create an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The history of New York begins around 10,000 BC, when the first Native Americans arrived. By 1100 AD, New York's main native cultures, the Iroquoian and Algonquian, had developed. European discovery of New York was led by the French in 1524 and the first land claim came in 1609 by the Dutch. As part of New Netherland, the colony was important in the fur trade and eventually became an agricultural resource thanks to the patroon system. In 1626 the Dutch bought the island of Manhattan from Native Americans.[1] In 1664, England renamed the colony New York, after the Duke of York (later James II & VII.) New York City gained prominence in the 18th century as a major trading port in the Thirteen Colonies.\", '', \"New York played a pivotal role during the American Revolution and subsequent war. The Stamp Act Congress in 1765 brought together representatives from across the Thirteen Colonies to form a unified response to British policies. The Sons of Liberty were active in New York City to challenge British authority. After a major loss at the Battle of Long Island, the Continental Army suffered a series of additional defeats that forced a retreat from the New York City area, leaving the strategic port and harbor to the British army and navy as their North American base of operations for the rest of the war. The Battle of Saratoga was the turning point of the war in favor of the Americans, convincing France to formally ally with them. New York's constitution was adopted in 1777, and strongly influenced the United States Constitution. New York City was the national capital at various times between 1785 and 1790, where the Bill of Rights was drafted. Albany became the permanent state capital in 1797. In 1787, New York became the eleventh state to ratify the United States Constitution.\", '', \"New York hosted significant transportation advancements in the 19th century, including the first steamboat line in 1807, the Erie Canal in 1825, and America's first regularly scheduled rail service in 1831. These advancements led to the expanded settlement of western New York and trade ties to the Midwest settlements around the Great Lakes.\", '', \"Due to New York City's trade ties to the South, there were numerous southern sympathizers in the early days of the American Civil War and the mayor proposed secession. Far from any of the battles, New York ultimately sent the most men and money to support the Union cause. Thereafter, the state helped create the industrial age and consequently was home to some of the first labor unions.\", '', 'During the 19th century, New York City became the main entry point for European immigrants to the United States, beginning with a wave of Irish during their Great Famine. Millions came through Castle Clinton in Battery Park before Ellis Island opened in 1892 to welcome millions more, increasingly from eastern and southern Europe. The Statue of Liberty opened in 1886 and became a symbol of hope. New York boomed during the Roaring Twenties, before the Wall Street Crash of 1929, and skyscrapers expressed the energy of the city. New York City was the site of successive tallest buildings in the world from 1913–74.', '', \"The buildup of defense industries for World War II turned around the state's economy from the Great Depression, as hundreds of thousands worked to defeat the Axis powers. Following the war, the state experienced significant suburbanization around all the major cities, and most central cities shrank. The Thruway system opened in 1956, signalling another era of transportation advances.\", '', \"Following a period of near–bankruptcy in the late 1970s, New York City renewed its stature as a cultural center, attracted more immigration, and hosted the development of new music styles. The city developed from publishing to become a media capital over the second half of the 20th century, hosting most national news channels and broadcasts. Some of its newspapers became nationally and globallyrenowned. The state's manufacturing base eroded with the restructuring of industry, and the state transitioned into service industries.\", '', 'The September 11 attacks of 2001 destroyed the World Trade Center, killing almost 3,000 people; they were the largest terrorist attacks on United States soil.']\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD from a text file\n",
    "\n",
    "lines = sc.textFile('data/word_count.text')\n",
    "\n",
    "print(lines.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD from a Python list\n",
    "\n",
    "series = sc.parallelize([1,2,3,4])\n",
    "print(series.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on RDD\n",
    "\n",
    "There are two types of operations on RDD:\n",
    "\n",
    "1. **Transformation**\n",
    "\n",
    "    Apply some **functions** to the data in RDD to **create a new RDD**;\n",
    "    \n",
    "2. **Action**:\n",
    "\n",
    "    Compute a **result** based on an RDD;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exmaple of transformation: filter\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (spark)",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
